#!/usr/bin/env python3
"""
Example usage of the Quality Validation Agent.

This example demonstrates how to use the AI-driven quality validation
system for AWS CloudOps exam questions.
"""

import asyncio
import json
import logging
from pathlib import Path
from typing import List

# Local imports
from config import AgentConfig
from core.quality_validation_agent import QualityValidationAgent
from models.question_models import Question, QuestionBatch, LearningResource
from models.validation_models import QuestionValidation, BatchValidation

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_sample_questions() -> List[Question]:
    """Load sample questions for validation."""
    return [
        Question(
            id="q001",
            domain="monitoring",
            difficulty="medium",
            type="single",
            question="""
EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã§å‹•ä½œã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€çªç„¶ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒé…ããªã‚Šã¾ã—ãŸã€‚
CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç¢ºèªã—ãŸã¨ã“ã‚ã€CPUä½¿ç”¨ç‡ã¯æ­£å¸¸ã§ã™ãŒã€ãƒ‡ã‚£ã‚¹ã‚¯I/Oå¾…æ©Ÿæ™‚é–“ãŒé«˜ããªã£ã¦ã„ã¾ã™ã€‚

ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«æœ€ã‚‚åŠ¹æœçš„ãªå¯¾ç­–ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ
            """.strip(),
            options=[
                "EBSãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’gp2ã‹ã‚‰gp3ã«å¤‰æ›´ã—ã€IOPSã‚’å¢—åŠ ã•ã›ã‚‹",
                "ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã‚’ã‚ˆã‚Šå¤§ããªã‚‚ã®ã«å¤‰æ›´ã™ã‚‹",
                "Auto Scalingã‚°ãƒ«ãƒ¼ãƒ—ã®æœ€å°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°ã‚’å¢—ã‚„ã™",
                "CloudFrontãƒ‡ã‚£ã‚¹ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¨­å®šã™ã‚‹"
            ],
            correct_answer="A",
            explanation="""
æ­£è§£ã¯Aã€ŒEBSãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’gp2ã‹ã‚‰gp3ã«å¤‰æ›´ã—ã€IOPSã‚’å¢—åŠ ã•ã›ã‚‹ã€ã§ã™ã€‚

**æ­£è§£ã®ç†ç”±:**
ãƒ‡ã‚£ã‚¹ã‚¯I/Oå¾…æ©Ÿæ™‚é–“ãŒé«˜ã„å ´åˆã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã£ã¦ã„ã¾ã™ã€‚
gp3ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¯gp2ã‚ˆã‚Šã‚‚é«˜ã„IOPSã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æä¾›ã§ãã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã‚’è§£æ±ºã§ãã¾ã™ã€‚

**ä»–ã®é¸æŠè‚¢ãŒä¸é©åˆ‡ãªç†ç”±:**
- B: CPUä½¿ç”¨ç‡ãŒæ­£å¸¸ãªãŸã‚ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚µã‚¤ã‚ºã®å¤‰æ›´ã¯åŠ¹æœçš„ã§ã¯ãªã„
- C: Auto Scalingã¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯å¢—åŠ ã«å¯¾ã™ã‚‹å¯¾ç­–ã§ã€I/Oå•é¡Œã®æ ¹æœ¬è§£æ±ºã«ãªã‚‰ãªã„
- D: CloudFrontã¯é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é…ä¿¡ã«æœ‰åŠ¹ã ãŒã€ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã®I/Oå•é¡Œã¯è§£æ±ºã—ãªã„
            """.strip(),
            learning_resources=[
                LearningResource(
                    title="Amazon EBS ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—",
                    url="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html",
                    type="documentation"
                )
            ],
            related_services=["EC2", "EBS", "CloudWatch"],
            tags=["performance", "storage", "troubleshooting"]
        ),
        Question(
            id="q002",
            domain="reliability",
            difficulty="hard",
            type="multiple",
            question="""
ãƒãƒ«ãƒAZæ§‹æˆã®RDSãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã€ãƒ—ãƒ©ã‚¤ãƒãƒªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«éšœå®³ãŒç™ºç”Ÿã—ãŸå ´åˆã®
è‡ªå‹•ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã‚’æœ€é©åŒ–ã—ãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚

ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼æ™‚é–“ã‚’æœ€å°åŒ–ã—ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å¯ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«
å®Ÿè£…ã™ã¹ãå¯¾ç­–ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿï¼ˆ2ã¤é¸æŠã—ã¦ãã ã•ã„ï¼‰
            """.strip(),
            options=[
                "RDS Proxyã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«ã‚’ç®¡ç†ã™ã‚‹",
                "Read Replicaã‚’è¤‡æ•°ã®AZã«é…ç½®ã™ã‚‹",
                "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³å†è©¦è¡Œãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã™ã‚‹",
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é »åº¦ã‚’å¢—ã‚„ã™",
                "RDSã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚µã‚¤ã‚ºã‚’å¤§ããã™ã‚‹"
            ],
            correct_answer=["A", "C"],
            explanation="""
æ­£è§£ã¯Aã¨Cã§ã™ã€‚

**A. RDS Proxyã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«ã‚’ç®¡ç†ã™ã‚‹**
- ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼æ™‚ã®ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†ã‚’æœ€é©åŒ–
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰ã®æ¥ç¶šã‚’åŠ¹ç‡çš„ã«å‡¦ç†
- ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼æ™‚é–“ã®çŸ­ç¸®ã«ç›´æ¥è²¢çŒ®

**C. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³å†è©¦è¡Œãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã™ã‚‹**
- ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ä¸­ã®ä¸€æ™‚çš„ãªæ¥ç¶šã‚¨ãƒ©ãƒ¼ã«å¯¾å¿œ
- è‡ªå‹•çš„ãªæ¥ç¶šå¾©æ—§ã«ã‚ˆã‚Šå¯ç”¨æ€§å‘ä¸Š
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã§ã®è€éšœå®³æ€§å¼·åŒ–

**ä»–ã®é¸æŠè‚¢ã«ã¤ã„ã¦:**
- B: Read Replicaã¯èª­ã¿å–ã‚Šå°‚ç”¨ã§ã€ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã«ã¯ç›´æ¥é–¢ä¸ã—ãªã„
- D: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é »åº¦ã¯ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼æ™‚é–“ã«å½±éŸ¿ã—ãªã„
- E: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚µã‚¤ã‚ºã¯ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼é€Ÿåº¦ã«å½±éŸ¿ã—ãªã„
            """.strip(),
            learning_resources=[
                LearningResource(
                    title="Amazon RDS Multi-AZ é…ç½®",
                    url="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html",
                    type="documentation"
                ),
                LearningResource(
                    title="RDS Proxy ã®ä½¿ç”¨",
                    url="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html",
                    type="documentation"
                )
            ],
            related_services=["RDS", "RDS Proxy"],
            tags=["high-availability", "failover", "database"]
        )
    ]


async def example_single_question_validation():
    """Example: Validate a single question."""
    logger.info("Example: Single Question Validation")
    logger.info("-" * 40)
    
    # Create configuration
    config = AgentConfig()
    
    # Create quality validation agent
    validator = QualityValidationAgent(config)
    
    # Load sample question
    questions = load_sample_questions()
    question = questions[0]
    
    logger.info(f"Validating question: {question.id}")
    logger.info(f"Domain: {question.domain}, Difficulty: {question.difficulty}")
    
    try:
        # Validate the question
        validation_result = validator.validate_question(question)
        
        # Display results
        print(f"\nğŸ“Š Validation Results for {question.id}")
        print(f"Overall Score: {validation_result.overall_score}/100")
        print(f"Technical Accuracy: {'âœ…' if validation_result.technical_accuracy else 'âŒ'}")
        print(f"Clarity Score: {validation_result.clarity_score}/10")
        print(f"Difficulty Appropriate: {'âœ…' if validation_result.difficulty_appropriate else 'âŒ'}")
        print(f"Japanese Quality: {validation_result.japanese_quality}/10")
        print(f"Approved: {'âœ…' if validation_result.approved else 'âŒ'}")
        
        if validation_result.issues:
            print(f"\nâš ï¸  Issues Identified:")
            for issue in validation_result.issues:
                print(f"  â€¢ {issue}")
        
        if validation_result.suggestions:
            print(f"\nğŸ’¡ Suggestions:")
            for suggestion in validation_result.suggestions:
                print(f"  â€¢ {suggestion}")
        
        return validation_result
        
    except Exception as e:
        logger.error(f"Validation failed: {e}")
        return None


async def example_batch_validation():
    """Example: Validate a batch of questions."""
    logger.info("\nExample: Batch Validation")
    logger.info("-" * 40)
    
    # Create configuration
    config = AgentConfig()
    
    # Create quality validation agent
    validator = QualityValidationAgent(config)
    
    # Create a batch from sample questions
    questions = load_sample_questions()
    
    # Extend to 10 questions by duplicating and modifying
    extended_questions = []
    for i in range(10):
        base_question = questions[i % len(questions)]
        question = Question(**base_question.model_dump())
        question.id = f"q{i+1:03d}"
        
        # Vary domains and difficulties
        domains = ["monitoring", "reliability", "deployment", "security", "networking"]
        difficulties = ["easy", "medium", "hard"]
        question.domain = domains[i % len(domains)]
        question.difficulty = difficulties[i % len(difficulties)]
        
        extended_questions.append(question)
    
    batch = QuestionBatch(
        batch_number=1,
        questions=extended_questions,
        target_domain="monitoring"
    )
    
    logger.info(f"Validating batch {batch.batch_number} with {len(batch.questions)} questions")
    
    try:
        # Validate the batch
        batch_validation = validator.validate_batch(batch)
        
        # Display results
        print(f"\nğŸ“Š Batch Validation Results")
        print(f"Batch Number: {batch_validation.batch_number}")
        print(f"Batch Quality Score: {batch_validation.batch_quality_score}/100")
        print(f"Approved Questions: {sum(1 for qv in batch_validation.question_validations if qv.approved)}/10")
        print(f"Batch Approved: {'âœ…' if batch_validation.batch_approved else 'âŒ'}")
        
        # Show individual question scores
        print(f"\nğŸ“ Individual Question Scores:")
        for qv in batch_validation.question_validations:
            status = "âœ…" if qv.approved else "âŒ"
            print(f"  {qv.question_id}: {qv.overall_score}/100 {status}")
        
        # Show validation summary
        if batch_validation.validation_summary:
            summary = batch_validation.validation_summary
            print(f"\nğŸ“ˆ Validation Summary:")
            print(f"  Technical Accuracy Rate: {summary.get('technical_accuracy_rate', 0):.1%}")
            print(f"  Explanation Completeness Rate: {summary.get('explanation_completeness_rate', 0):.1%}")
            print(f"  Average Japanese Quality: {summary.get('average_japanese_quality', 0):.1f}/10")
            print(f"  Issues Identified: {summary.get('issues_identified', 0)}")
        
        if batch_validation.required_fixes:
            print(f"\nğŸ”§ Required Fixes:")
            for fix in batch_validation.required_fixes:
                print(f"  â€¢ {fix}")
        
        if batch_validation.recommendations:
            print(f"\nğŸ’¡ Recommendations:")
            for rec in batch_validation.recommendations:
                print(f"  â€¢ {rec}")
        
        return batch_validation
        
    except Exception as e:
        logger.error(f"Batch validation failed: {e}")
        return None


async def example_duplicate_detection():
    """Example: Detect duplicate questions."""
    logger.info("\nExample: Duplicate Detection")
    logger.info("-" * 40)
    
    # Create configuration
    config = AgentConfig()
    
    # Create quality validation agent
    validator = QualityValidationAgent(config)
    
    # Load existing questions
    existing_questions = load_sample_questions()
    
    # Create a new question that's similar to an existing one
    similar_question = Question(
        id="q003",
        domain="monitoring",
        difficulty="medium",
        type="single",
        question="""
EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒçªç„¶é…ããªã‚Šã¾ã—ãŸã€‚
CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç¢ºèªã™ã‚‹ã¨ã€CPUä½¿ç”¨ç‡ã¯æ­£å¸¸ã§ã™ãŒã€ãƒ‡ã‚£ã‚¹ã‚¯I/Oå¾…æ©Ÿæ™‚é–“ãŒé«˜ã„çŠ¶æ…‹ã§ã™ã€‚

ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«æœ€ã‚‚åŠ¹æœçš„ãªå¯¾ç­–ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ
        """.strip(),
        options=[
            "EBSãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’gp2ã‹ã‚‰gp3ã«å¤‰æ›´ã—ã€IOPSã‚’å¢—åŠ ã•ã›ã‚‹",
            "ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã‚’ã‚ˆã‚Šå¤§ããªã‚‚ã®ã«å¤‰æ›´ã™ã‚‹",
            "Auto Scalingã‚°ãƒ«ãƒ¼ãƒ—ã®æœ€å°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°ã‚’å¢—ã‚„ã™",
            "CloudFrontãƒ‡ã‚£ã‚¹ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¨­å®šã™ã‚‹"
        ],
        correct_answer="A",
        explanation="Similar explanation...",
        learning_resources=[
            LearningResource(
                title="Amazon EBS ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—",
                url="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html",
                type="documentation"
            )
        ],
        related_services=["EC2", "EBS", "CloudWatch"],
        tags=["performance", "storage", "troubleshooting"]
    )
    
    # Create a completely different question
    different_question = Question(
        id="q004",
        domain="security",
        difficulty="hard",
        type="single",
        question="IAMãƒ­ãƒ¼ãƒ«ã¨IAMãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»ãªé•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        options=[
            "IAMãƒ­ãƒ¼ãƒ«ã¯ä¸€æ™‚çš„ãªèªè¨¼æƒ…å ±ã‚’æä¾›ã™ã‚‹",
            "IAMãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ°¸ç¶šçš„ãªã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’æŒã¤",
            "IAMãƒ­ãƒ¼ãƒ«ã¯AWSã‚µãƒ¼ãƒ“ã‚¹å°‚ç”¨ã§ã‚ã‚‹",
            "IAMãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ†ã‚£ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã®ã¿å¯èƒ½"
        ],
        correct_answer="A",
        explanation="IAMãƒ­ãƒ¼ãƒ«ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é•ã„ã«ã¤ã„ã¦ã®èª¬æ˜...",
        learning_resources=[
            LearningResource(
                title="IAM ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰",
                url="https://docs.aws.amazon.com/iam/",
                type="documentation"
            )
        ],
        related_services=["IAM"],
        tags=["security", "identity", "access-management"]
    )
    
    logger.info("Testing duplicate detection...")
    
    try:
        # Test similar question
        similar_result = validator.validate_question_against_existing(
            similar_question, existing_questions
        )
        
        # Test different question
        different_result = validator.validate_question_against_existing(
            different_question, existing_questions
        )
        
        # Display results
        print(f"\nğŸ” Duplicate Detection Results")
        
        print(f"\nğŸ“ Similar Question ({similar_question.id}):")
        print(f"  Has Duplicates: {'âš ï¸  Yes' if similar_result['has_duplicates'] else 'âœ… No'}")
        print(f"  Recommendation: {similar_result['recommendation']}")
        if similar_result['similar_questions']:
            print(f"  Similar to:")
            for sim in similar_result['similar_questions']:
                print(f"    â€¢ {sim['id']} (similarity: {sim['similarity']:.2f}) - {sim['reason']}")
        
        print(f"\nğŸ“ Different Question ({different_question.id}):")
        print(f"  Has Duplicates: {'âš ï¸  Yes' if different_result['has_duplicates'] else 'âœ… No'}")
        print(f"  Recommendation: {different_result['recommendation']}")
        if different_result['similar_questions']:
            print(f"  Similar to:")
            for sim in different_result['similar_questions']:
                print(f"    â€¢ {sim['id']} (similarity: {sim['similarity']:.2f}) - {sim['reason']}")
        
        return similar_result, different_result
        
    except Exception as e:
        logger.error(f"Duplicate detection failed: {e}")
        return None, None


async def example_quality_report():
    """Example: Generate a comprehensive quality report."""
    logger.info("\nExample: Quality Report Generation")
    logger.info("-" * 40)
    
    # Create configuration
    config = AgentConfig()
    
    # Create quality validation agent
    validator = QualityValidationAgent(config)
    
    # Create multiple batches for the report
    batch_validations = []
    
    logger.info("Creating sample batch validations...")
    
    # Create 3 sample batches with different quality levels
    for batch_num in range(1, 4):
        questions = load_sample_questions()
        
        # Extend to 10 questions
        extended_questions = []
        for i in range(10):
            base_question = questions[i % len(questions)]
            question = Question(**base_question.model_dump())
            question.id = f"q{(batch_num-1)*10 + i + 1:03d}"
            extended_questions.append(question)
        
        batch = QuestionBatch(
            batch_number=batch_num,
            questions=extended_questions
        )
        
        # Validate batch
        batch_validation = validator.validate_batch(batch)
        batch_validations.append(batch_validation)
    
    logger.info(f"Generating quality report for {len(batch_validations)} batches...")
    
    try:
        # Generate comprehensive quality report
        quality_report = validator.generate_quality_report(batch_validations)
        
        # Display report summary
        print(f"\nğŸ“Š Quality Report Summary")
        print(f"Report Generated: {quality_report['report_generated_at']}")
        
        summary = quality_report['summary']
        print(f"\nğŸ“ˆ Overall Statistics:")
        print(f"  Total Batches: {summary['total_batches']}")
        print(f"  Total Questions: {summary['total_questions']}")
        print(f"  Approved Questions: {summary['approved_questions']}")
        print(f"  Approval Rate: {summary['approval_rate']:.1%}")
        print(f"  Average Overall Score: {summary['average_overall_score']:.1f}/100")
        print(f"  Technical Accuracy Rate: {summary['technical_accuracy_rate']:.1%}")
        print(f"  Average Japanese Quality: {summary['average_japanese_quality']:.1f}/10")
        
        # Show batch details
        print(f"\nğŸ“ Batch Details:")
        for batch_detail in quality_report['batch_details']:
            status = "âœ…" if batch_detail['approved'] else "âŒ"
            print(f"  Batch {batch_detail['batch_number']}: {batch_detail['batch_score']}/100 "
                  f"({batch_detail['approved_questions']}/10 approved) {status}")
        
        # Show quality metrics
        metrics = quality_report['quality_metrics']
        print(f"\nğŸ¯ Quality Metrics:")
        print(f"  High Quality Batches (â‰¥85): {metrics['high_quality_batches']}")
        print(f"  Medium Quality Batches (70-84): {metrics['medium_quality_batches']}")
        print(f"  Low Quality Batches (<70): {metrics['low_quality_batches']}")
        print(f"  Batches Needing Revision: {metrics['batches_needing_revision']}")
        
        # Show recommendations
        if quality_report['recommendations']:
            print(f"\nğŸ’¡ Overall Recommendations:")
            for rec in quality_report['recommendations']:
                print(f"  â€¢ {rec}")
        
        # Save report to file
        output_dir = Path("output/quality_validation_examples")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        with open(output_dir / "example_quality_report.json", "w", encoding="utf-8") as f:
            json.dump(quality_report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Quality report saved to {output_dir / 'example_quality_report.json'}")
        
        return quality_report
        
    except Exception as e:
        logger.error(f"Quality report generation failed: {e}")
        return None


async def main():
    """Run all quality validation examples."""
    print("ğŸš€ Quality Validation Agent Examples")
    print("=" * 50)
    
    try:
        # Example 1: Single question validation
        await example_single_question_validation()
        
        # Example 2: Batch validation
        await example_batch_validation()
        
        # Example 3: Duplicate detection
        await example_duplicate_detection()
        
        # Example 4: Quality report generation
        await example_quality_report()
        
        print(f"\nâœ… All examples completed successfully!")
        print(f"Check the 'output/quality_validation_examples/' directory for detailed results.")
        
    except Exception as e:
        logger.error(f"Examples failed: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())